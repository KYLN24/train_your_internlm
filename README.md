# ä»å¤´è®­ç»ƒä¸€ä¸ª InternLM

> æœ¬æ–‡æ¡£éƒ¨åˆ†å†…å®¹æ¥è‡ª[InternLM](https://github.com/InternLM/InternLM)ã€‚
> 
> æœ¬æ–‡æ¡£ä»…èµ·åˆ°ä»‹ç» InternLM è®­ç»ƒæ¡†æ¶çš„ä½œç”¨ã€‚å®Œå…¨ä¾ç…§æœ¬æ–‡æ¡£çš„æ­¥éª¤æ“ä½œå¹¶ä¸èƒ½è®©ä½ è·å¾—ä¸€ä¸ªå’Œ [internlm/internlm-7b](https://huggingface.co/internlm/internlm-7b) èƒ½åŠ›ç›¸å½“çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•ä½¿ç”¨ InternLM å®˜æ–¹è®­ç»ƒä»£ç åœ¨ [The Pile](https://arxiv.org/abs/2101.00027) æ•°æ®é›†ä¸Šå®Œæˆå…·æœ‰ 70 äº¿å‚æ•°çš„ InternLM æ¨¡å‹çš„é¢„è®­ç»ƒã€‚

é¦–å…ˆï¼Œè¯·å°†æœ¬ç¤ºä¾‹é¡¹ç›® clone åˆ°æœ¬åœ°ã€‚

``` sh
git clone git@github.com:KYLN24/train_your_internlm.git --recursive
```

ä¸Šè¿°å‘½ä»¤ä¼šå°†æœ¬é¡¹ç›®å’Œ [InternLM](https://github.com/InternLM/InternLM) åŠå…¶ä¾èµ–é¡¹å…¨éƒ¨ clone è‡³å½“å‰ç›®å½•ä¸‹çš„ `train_your_internlm` æ–‡ä»¶å¤¹ä¸­ã€‚

## ğŸ–¥ï¸ é…ç½®è®­ç»ƒç¯å¢ƒ

å‚è€ƒ [InternLM/doc/install.md](InternLM/doc/install.md#ç¯å¢ƒå‡†å¤‡) é…ç½®è®­ç»ƒç¯å¢ƒã€‚

ä½ éœ€è¦ä¸€å°è¿è¡Œ Linux ç³»ç»Ÿçš„è®¡ç®—æœºã€‚è¯·è‡ªè¡Œå®‰è£… [CUDA Toolkit 11.7](https://developer.nvidia.com/cuda-11-7-1-download-archive) å’Œ GCC 10.2ã€‚

### ã€å¯é€‰ã€‘å®‰è£… Conda

``` sh
wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && sh ./Miniconda3-latest-Linux-x86_64.sh
```

### ã€å¯é€‰ã€‘åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

``` sh
conda create --name internlm-env python=3.10 -y
conda activate internlm-env
```

### å®‰è£… InternLM ä¾èµ–

``` sh
cd InternLM/internlm
pip install -r requirements/torch.txt 
pip install -r requirements/runtime.txt 
```

### å®‰è£… flash-attention (version v1.0.5)
```bash
cd InternLM/third_party/flash-attention
python setup.py install
cd ./csrc
cd fused_dense_lib && pip install -v .
cd ../xentropy && pip install -v .
cd ../rotary && pip install -v .
cd ../layer_norm && pip install -v .
cd ../../../../
```

### å®‰è£… Apex (version 23.05)
```bash
cd InternLM/third_party/apex
pip install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
cd ../../
```

## ğŸ—ƒï¸ å‡†å¤‡æ•°æ®é›†

å®Œæ•´çš„ The Pile æ•°æ®é›†å¤§å°ä¸º 825GBã€‚ä¸ºä¾¿äºå®éªŒï¼Œè¿™é‡Œä»¥ [ola13/small-the_pile](https://huggingface.co/datasets/ola13/small-the_pile) æ•°æ®é›†ä¸ºä¾‹ï¼Œä»‹ç»æ•°æ®çš„å¤„ç†ã€‚

ä½ å¯ä»¥ä» Hugging Face ä¸Šè·å–è¯¥æ•°æ®é›†ã€‚é¦–å…ˆå®‰è£… Hugging Face Datasets

``` sh
pip install datasets
```

ç„¶åè¿è¡Œ [data/get_dataset.py](data/get_dataset.py)ã€‚

``` sh
python -u data/get_dataset.py
```

æ¥ä¸‹æ¥ä½¿ç”¨ InternLM æä¾›çš„å·¥å…· [InternLM/tools/tokenizer.py](InternLM/tools/tokenizer.py) å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç† tokenizationã€‚`tokenizer.py` æ”¯æŒå¤„ç† `.txt`ã€`.json`æˆ–`.jsonl` æ ¼å¼çš„æ•°æ®ã€‚è¯¦æƒ…è¯·å‚è€ƒ [InternLM/doc/usage.md](InternLM/doc/usage.md#æ•°æ®å‡†å¤‡-å¾®è°ƒ)

`get_dataset.py` å·²ç»å°†æ•°æ®é›†ä»¥ `jsonl` æ ¼å¼ä¿å­˜åœ¨äº† `data/train` å’Œ `data/train` ä¸‹ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ `tokenizer.py` æ¥å¤„ç†ã€‚

```
python InternLM/tools/tokenizer.py --text_input_path=./data/train/small-the_pile.train.jsonl --bin_output_path=./data/train/en/small-the_pile.train.bin

python InternLM/tools/tokenizer.py --text_input_path=./data/val/small-the_pile.val.jsonl --bin_output_path=./data/val/en/small-the_pile.val.bin
```

è¯·æ³¨æ„ï¼Œç”Ÿæˆçš„æ•°æ®æ–‡ä»¶ (\*.binå’Œ\*.bin.meta) åº”å½“æŒ‰ç…§ç±»åˆ«æ”¾ç½®äº `cn`ã€`en` æˆ– `code` æ–‡ä»¶å¤¹ä¸­ã€‚

## ğŸ› ï¸ è‡ªå®šä¹‰è®­ç»ƒé…ç½®ä¸è¶…å‚æ•°

ä¿®æ”¹ [7b_pretrain_config.py](7b_pretrain_config.py)ã€‚ä½ å¯ä»¥è‡ªå®šä¹‰è®­ç»ƒæ­¥æ•°ã€æ‰¹å¤§å°ã€æ•°æ®é›†è·¯å¾„ã€æ¨¡å‹ä¿å­˜è·¯å¾„ã€å­¦ä¹ ç‡ä¸å…¶ä»–ä¼˜åŒ–å™¨å‚æ•°ã€å’Œå¤šå¡å¹¶è¡Œé…ç½®ç­‰ã€‚æ›´å¤šé…ç½®é¡¹è¯·å‚è€ƒ [InternLM/configs/7B_sft.py](InternLM/configs/7B_sft.py)

## ğŸš€ å¯åŠ¨è®­ç»ƒ

ä½¿ç”¨ Slurm å¯åŠ¨è®­ç»ƒ

``` sh
srun -p llm_o -N 1 -n 8 --ntasks-per-node=8 --gpus-per-task=1 python -u ./InternLM/train.py --config=./7b_pretrain_config.py
``` 

ä½¿ç”¨ `torchrun` å¯åŠ¨è®­ç»ƒ

```
torchrun --nproc_per_node=8 ./InternLM/train.py --config=./7b_pretrain_config.py`
```

ä½¿ç”¨ TensorBoard ç›‘æ§è®­ç»ƒè¯¦æƒ…

```
tensorboard --logdir=logs
```

ä½¿ç”¨æœ¬æ–‡æ¡£æä¾›çš„é…ç½®æ–‡ä»¶åœ¨ 8x A800 80GB ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒTGS åº”è¯¥è¾¾åˆ° 4103 å·¦å³ï¼ŒTFLOPS è¾¾åˆ° 183 å·¦å³ã€‚è®­ç»ƒæ€§èƒ½è¯·å‚è€ƒ [InternLM/doc/train_performance.md](InternLM/doc/train_performance.md)ã€‚

## ğŸ¤— è½¬æ¢ä¸º Hugging Face æ ¼å¼

ä¸ºäº†æ–¹ä¾¿åç»­å·¥ä½œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ [InternLM/tools/transformers/convert2hf.py](InternLM/tools/transformers/convert2hf.py) å°†ä¿å­˜çš„ checkpoint è½¬æ¢ä¸º Hugging Face æ ¼å¼ã€‚è¯¦è§ [InternLM/tools/transformers/README-zh-Hans.md](InternLM/tools/transformers/README-zh-Hans.md)ã€‚

```
cd InternLM
python -u tools/transformers/convert2hf.py --src_folder=../ckpts/7b_pretrain/<select one ckpt> --tgt_folder=../ckpts/7b_pretrain/hf --tokenizer tools/V7_sft.model
cd ..
```

é¢„è§ˆä¸€ä¸‹æ¨¡å‹çš„ç”Ÿæˆæ•ˆæœ

```
python -u test.py
```
